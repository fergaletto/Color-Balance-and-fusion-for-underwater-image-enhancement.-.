{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled",
      "provenance": [],
      "authorship_tag": "ABX9TyNeldhnvyKE2lZxKvWHRqj3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fergaletto/Color-Balance-and-fusion-for-underwater-image-enhancement.-./blob/master/moving_object_siamese_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFVcC0e_SLMz"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1XXKBu7SQwT"
      },
      "source": [
        "from keras.layers import Input, Conv2D, Lambda, merge, Dense, Flatten,MaxPooling2D,Activation, Dropout\r\n",
        "from keras.models import Model, Sequential\r\n",
        "from keras.regularizers import l2\r\n",
        "from keras import backend as K\r\n",
        "from keras.optimizers import Adam\r\n",
        "from skimage.io import imshow\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KC3coIWSVIP",
        "outputId": "f8a9ceef-6088-455f-9d83-b58fa7a8b75f"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0mjpB26SxWk"
      },
      "source": [
        "# Set the directories. \r\n",
        "DATA_PATH = '/content/gdrive/My Drive/Siamese/'\r\n",
        "SIMILAR_PATH = DATA_PATH+ 'noise'\r\n",
        "DIFFERENT_PATH = DATA_PATH+ 'moving'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dH-alW_hwaj9"
      },
      "source": [
        "# Prepare the dataset from the folders generated in matlab. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7At4YdvPSYte"
      },
      "source": [
        "import os\r\n",
        "import json \r\n",
        "import shutil\r\n",
        "\r\n",
        "\r\n",
        "json_file = DATA_PATH + 'labels.json' # the input json file\r\n",
        "dest_folder = DATA_PATH + 'DATASET'\r\n",
        "\r\n",
        "if not os.path.exists(dest_folder):\r\n",
        "    os.mkdir(dest_folder)\r\n",
        "\r\n",
        "\r\n",
        "def produce_pair(pairs_directory, label, json_file):\r\n",
        "  # This function reads a folder which contains pair of patches (enfing in a.png\r\n",
        "  # and split them into two separate lists + label.\r\n",
        "  # Opening Jason file\r\n",
        "  f = open(json_file)\r\n",
        "  new_data = {'left_input': '017-001-004575a.png','right_input': '017-001-004575b.png','label': 'noise'}\r\n",
        "  # return object as a dictionaty\r\n",
        "  data = json.load(f)\r\n",
        "  for root, dirs, files in os.walk(pairs_directory):\r\n",
        "      for f in files:\r\n",
        "        if (f[-5:]=='a.png'):\r\n",
        "          new_data['left_input'] = f\r\n",
        "          new_data['right_input'] = f[:-5]+'b.png'\r\n",
        "          new_data['label'] = label\r\n",
        "          #print(new_data)\r\n",
        "          data.append(new_data)\r\n",
        "\r\n",
        "        # move the images to the destination folder.\r\n",
        "        original = pairs_directory  + '/' + f\r\n",
        "        target = dest_folder + '/' + f\r\n",
        "        shutil.copyfile(original, target)\r\n",
        "\r\n",
        "  with open(json_file, \"w\") as outfile: \r\n",
        "      json.dump(data, outfile,  indent=4)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "produce_pair(SIMILAR_PATH, 'noise', json_file);\r\n",
        "produce_pair(DIFFERENT_PATH, 'moving', json_file);\r\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKUHxSTrwg_9"
      },
      "source": [
        "# Create a pickle file with the dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbHNmiqKu7Ri"
      },
      "source": [
        "## Data Creation\r\n",
        "import cv2\r\n",
        "\r\n",
        "data_dir = DATA_PATH + 'DATASET'\r\n",
        "labels_file = DATA_PATH + 'labels.json'\r\n",
        "\r\n",
        "classes = ['noise', 'moving']\r\n",
        "\r\n",
        "def create_data(input_dir, labels):\r\n",
        "    X_left = []\r\n",
        "    X_right = []\r\n",
        "    Y = []\r\n",
        "    # Opening Jason file\r\n",
        "    f = open(labels)\r\n",
        "    data = json.load(f)\r\n",
        "    for r in data: \r\n",
        "        X_left.append(cv2.imread(input_dir+'/'+r['left_input']))\r\n",
        "        X_right.append(cv2.imread(input_dir+'/'+r['right_input']))\r\n",
        "        Y.append(classes.index(r[\"label\"]))\r\n",
        "    \r\n",
        "    X_left = np.asarray(X_left)\r\n",
        "    X_right = np.asarray(X_right)\r\n",
        "    Y = np.asarray(Y)\r\n",
        "    return X_left,X_right, Y\r\n",
        "\r\n",
        "  ## Create dataset\r\n",
        "left_input,right_input, targets = create_data(data_dir, labels_file)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qvI2NFRu70e"
      },
      "source": [
        "# Randomize the data\r\n",
        "\r\n",
        "samples = left_input.shape[0];\r\n",
        "indices = np.arange(samples)\r\n",
        "np.random.shuffle(indices)\r\n",
        "\r\n",
        "left_input = left_input[indices]\r\n",
        "right_input = right_input[indices]\r\n",
        "targets = targets[indices]\r\n",
        "\r\n",
        "# split test and train data. \r\n",
        "X_left_train = left_input[:8*(samples//10)]\r\n",
        "X_rigth_train = right_input[:8*(samples//10)] \r\n",
        "Y_train = targets[:8*(samples//10)] \r\n",
        "\r\n",
        "X_left_test = left_input[8*(samples//10):]\r\n",
        "X_rigth_test = right_input[8*(samples//10):] \r\n",
        "Y_test = targets[8*(samples//10):] \r\n",
        "\r\n",
        "# Save pickle dataset\r\n",
        "import pickle\r\n",
        "\r\n",
        "with open(DATA_PATH + 'train.pickle', 'wb') as f:\r\n",
        "    pickle.dump([X_left_train,X_rigth_train,Y_train,X_left_test,X_rigth_test,Y_test], f)\r\n"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1qKU1M98fe_"
      },
      "source": [
        "# START FROM A SAVED PICKLE FILE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NkcPysJ5AcS"
      },
      "source": [
        "import pickle\r\n",
        "\t\r\n",
        "with open(DATA_PATH + 'train.pickle', 'rb') as f:\r\n",
        "    X_left_train,X_rigth_train,Y_train,X_left_test,X_rigth_test,Y_test = pickle.load(f)\r\n",
        "\r\n"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzKwvy5b9gW6"
      },
      "source": [
        "# Creating the structure of Siamese Network\r\n",
        "\r\n",
        "break it into some steps:\r\n",
        "1. 2 Inputs for each images\r\n",
        "2. Creating a network which both images will go through individually\r\n",
        "3. Couple the network to each input\r\n",
        "4. Calculate the L1 distance between them. Just (x1,y1)-(x2,y2)\r\n",
        "5. 1 Added layer that will say 1 if they are the same and 0 if they are \r\n",
        "\r\n",
        "## Create two Inputs for each image - left_input and right_input\r\n",
        "Hint - use Input Function in Keras and keep the shape to be the same as the data size. \r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdKEiejF5A-9"
      },
      "source": [
        "left_input  = Input(X_left_train.shape[1:])\r\n",
        "right_input = Input(X_rigth_train.shape[1:])"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUdtgJBE-ww1"
      },
      "source": [
        "# Create a base Network in which both images will go through individually.\r\n",
        "\r\n",
        "Sequential Model in Keras with convolution layers, Maxpooling Layers, Flatten Layer and Denser Layer with appropriate activation functions.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTXp_uC-7kPU"
      },
      "source": [
        "del base_network\r\n",
        "base_network = Sequential([\r\n",
        "               Conv2D(3,3,input_shape=X_left_train.shape[1:]), \r\n",
        "               Activation('relu'),\r\n",
        "               Conv2D(3,3),   \r\n",
        "               Activation('relu'),\r\n",
        "               MaxPooling2D(),\r\n",
        "                Conv2D(7,2),   #(N,35,35,5) -> (N,34,34,7)\r\n",
        "               Activation('relu'),\r\n",
        "               Flatten(), \r\n",
        "               Dense(8),\r\n",
        "               Activation('sigmoid') #(N,18) \r\n",
        "                               ])"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feM6RfKP_7bC"
      },
      "source": [
        "# Process the left and right inputs to the same Base Network(base_network)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kl_eoi86-fSx"
      },
      "source": [
        "processed_a = base_network(left_input)\r\n",
        "processed_b = base_network(right_input)"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oB3lXtCUAKg9"
      },
      "source": [
        "# Get the L1 Distance layer between the 2 processed encodings (processed_a and processed_b)\r\n",
        " use Lambda function for this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGdHrVhhADC8"
      },
      "source": [
        "L1_layer = Lambda(lambda tensor:K.abs(tensor[0] - tensor[1]))"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMJoN2x8AHns"
      },
      "source": [
        "L1_distance = L1_layer([processed_a , processed_b])"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxp3IXcCAUNb"
      },
      "source": [
        "# Add the prediction layer in the end and create the Siamese Network using Model function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9IBlOdVAQe0"
      },
      "source": [
        "prediction = Dense(1,activation='sigmoid')(L1_distance)\r\n",
        "\r\n",
        "siamese_net = Model(inputs=[left_input,right_input],outputs=prediction)"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zx9XJNGUAcOS"
      },
      "source": [
        "# Define the Optimizer Adam and Compile the Siamese Model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEDUaZaXAXzT"
      },
      "source": [
        "optimizer = Adam(0.001,decay = 1e-4)\r\n",
        "siamese_net.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8P78n0XAlKe",
        "outputId": "f158005a-6031-4fd0-8b66-ddd0f09cb977"
      },
      "source": [
        "siamese_net.summary()"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            [(None, 16, 16, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_5 (InputLayer)            [(None, 16, 16, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential_4 (Sequential)       (None, 8)            1667        input_4[0][0]                    \n",
            "                                                                 input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, 8)            0           sequential_4[0][0]               \n",
            "                                                                 sequential_4[1][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 1)            9           lambda_2[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 1,676\n",
            "Trainable params: 1,676\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABkRN-2xAwAt"
      },
      "source": [
        "# Training!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CuBUTdiGAlm0",
        "outputId": "21ce37aa-b600-4948-d504-76c8011ebc58"
      },
      "source": [
        "siamese_net.fit([X_left_train,X_rigth_train], Y_train,\r\n",
        "          batch_size=32,\r\n",
        "          epochs=30,\r\n",
        "          verbose=1,\r\n",
        "          validation_data=([X_left_test,X_rigth_test],Y_test))"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "71/71 [==============================] - 1s 15ms/step - loss: 0.4658 - accuracy: 0.9858 - val_loss: 0.3095 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2213 - accuracy: 1.0000 - val_loss: 0.1517 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.1038 - accuracy: 1.0000 - val_loss: 0.0700 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.0572 - accuracy: 1.0000 - val_loss: 0.0483 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.0432 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.0355 - accuracy: 1.0000 - val_loss: 0.0323 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.0301 - accuracy: 1.0000 - val_loss: 0.0277 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.0260 - accuracy: 1.0000 - val_loss: 0.0242 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.0228 - accuracy: 1.0000 - val_loss: 0.0214 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 0.0190 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.0170 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.0154 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.0139 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.0127 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.0107 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f769bf5afd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2p_CI6kfBb3P"
      },
      "source": [
        "# SAve the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTABA0lgBdB0"
      },
      "source": [
        "siamese_net.save(DATA_PATH+'model2.h5')"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNEvo0PVBqN0"
      },
      "source": [
        "# evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2MeFm6jBpPT",
        "outputId": "a07104c6-8f7b-41f1-e8b9-d9728188fc57"
      },
      "source": [
        "import keras\r\n",
        "model = keras.models.load_model(DATA_PATH+'model.h5')\r\n",
        "import numpy as np\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "y_pred = model.predict([X_left_test,X_rigth_test])\r\n",
        "\r\n",
        "\r\n",
        "print(classification_report(Y_test, np.round(y_pred)))"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       259\n",
            "           1       1.00      1.00      1.00       305\n",
            "\n",
            "    accuracy                           1.00       564\n",
            "   macro avg       1.00      1.00      1.00       564\n",
            "weighted avg       1.00      1.00      1.00       564\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "yM3R_tn_CRnW",
        "outputId": "5a85de41-13da-46b5-cf52-624547ee667a"
      },
      "source": [
        "\r\n",
        "\r\n",
        "# COnfusion matrix\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sn\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "\r\n",
        "ax= plt.subplot()\r\n",
        "sn.heatmap(confusion_matrix(Y_test, np.round(y_pred)), annot=True, ax = ax)\r\n",
        "#plt.show()\r\n",
        "# labels, title and ticks\r\n",
        "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \r\n",
        "ax.set_title('Confusion Matrix'); \r\n",
        "ax.xaxis.set_ticklabels(classes, rotation = 90); ax.yaxis.set_ticklabels(classes, rotation = 0);\r\n",
        "\r\n"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVJtS_ixCfTA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}